{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing folder d9d4762c8639fe76553c81ce159b3e45\n",
      "Creating folderd9d4762c8639fe76553c81ce159b3e45\n",
      "Removing existing folder 71256e28c1393f391385a21ab14f78f6\n",
      "Creating folder71256e28c1393f391385a21ab14f78f6\n",
      "Removing existing folder 0186092a96f773bafb62721eb4399c6b\n",
      "Creating folder0186092a96f773bafb62721eb4399c6b\n",
      "Removing existing folder 3acdb3ed962b2087fbe325514b098101\n",
      "Creating folder3acdb3ed962b2087fbe325514b098101\n",
      "Removing existing folder 63495a0c6f833359218e7c7f991746ab\n",
      "Creating folder63495a0c6f833359218e7c7f991746ab\n",
      "Removing existing folder d859a8c563558b7db0b73c6170ad84fd\n",
      "Creating folderd859a8c563558b7db0b73c6170ad84fd\n",
      "Removing existing folder 0b10c4d5df6cb25fa12a67f7e72580ab\n",
      "Creating folder0b10c4d5df6cb25fa12a67f7e72580ab\n",
      "Removing existing folder 517539cee7b8ea5909150998f5486a17\n",
      "Creating folder517539cee7b8ea5909150998f5486a17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "\n",
    "metadata_file = 'published-WGS-datasets-3-8-2021.csv'\n",
    "datasets = pd.read_csv( metadata_file )\n",
    "\n",
    "for dataset in datasets.iterrows():\n",
    "    directory = dataset[1]['e.uuid']\n",
    "    p = Path( directory )\n",
    "    \n",
    "    if p.exists() and p.is_dir():\n",
    "        print('Removing existing folder ' + directory)\n",
    "        rmtree(p)\n",
    "        print('Creating folder' + directory)\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        print('Creating folder' + directory)\n",
    "        p.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biosample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['id_namespace', 'local_id', 'project_id_namespace', 'project_local_id', 'persisten_id', 'creation_time', 'anatomy']\n",
    "\n",
    "df = pd.DataFrame(columns=headers)\n",
    "\n",
    "filename = 'biosample.tsv'\n",
    "for dataset in datasets.iterrows():\n",
    "    directory = dataset[1]['e.uuid']\n",
    "    df.to_csv(directory+'/'+filename, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_namespace = 'HuBMAP'\n",
    "local_id = 'University of Florida TMC'\n",
    "\n",
    "headers = ['id_namespace', 'local_id', 'persistent_id', 'creation_time', 'abbreviation', 'name', 'description']\n",
    "df = pd.DataFrame(columns=headers)\n",
    "df = df.append({'id_namespace':id_namespace, 'local_id':local_id, 'name':local_id}, ignore_index=True)\n",
    "\n",
    "filename = 'project.tsv'\n",
    "for dataset in datasets.iterrows():\n",
    "    directory = dataset[1]['e.uuid']\n",
    "    df.to_csv(directory+'/'+filename, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_namespace = 'HuBMAP'\n",
    "\n",
    "headers = ['id_namespace', 'local_id', 'persistent_id', 'creation_time', 'abbreviation', 'name', 'description']\n",
    "df = pd.DataFrame(columns=headers)\n",
    "\n",
    "filename = 'collection.tsv'\n",
    "for dataset in datasets.iterrows():\n",
    "    directory = dataset[1]['e.uuid']\n",
    "    local_id = dataset[1]['hubmap_id']\n",
    "    name = dataset[1]['hubmap_id']\n",
    "    \n",
    "    df = pd.DataFrame(columns=headers)\n",
    "    df = df.append({'id_namespace':id_namespace, 'local_id':local_id, 'name':local_id}, ignore_index=True)\n",
    "\n",
    "    df.to_csv(directory+'/'+filename, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory does not exist\n",
      "Data directory does not exist\n",
      "Data directory does not exist\n",
      "Data directory does not exist\n",
      "Data directory does not exist\n",
      "Data directory does not exist\n",
      "Data directory does not exist\n",
      "Data directory does not exist\n"
     ]
    }
   ],
   "source": [
    "id_namespace = 'HuBMAP'\n",
    "\n",
    "headers = ['id_namespace', 'local_id', 'project_id', 'persisten_id', 'creation_time', 'size_in_bytes', 'uncompressed_size_in_bytes', 'sha256','md5','filename','file_format', 'data_type', 'assay_type','mime_type']\n",
    "df = pd.DataFrame(columns=headers)\n",
    "\n",
    "filename = 'file.tsv'\n",
    "for dataset in datasets.iterrows():\n",
    "    directory = dataset[1]['e.uuid']\n",
    "    data_directory = Path(dataset[1]['m.local_directory_url_path'])\n",
    "    \n",
    "    if not data_directory.exists():\n",
    "        print('Data directory does not exist')\n",
    "        \n",
    "    df.to_csv(directory+'/'+filename, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
